# üèóÔ∏è Airflow on Kubernetes ‚Äî Architecture & Beginner Guide

Hey there! Ready to understand how Airflow runs on Kubernetes? This guide explains everything in plain English‚Äîno PhD required! We'll cover what each component does and give you a step-by-step walkthrough. üöÄ

> **üéØ Learning Goal:** By the end, you'll understand exactly how Airflow's pieces fit together and why Kubernetes makes it awesome.

## üí° High-Level Idea
- Airflow schedules and runs your workflows (DAGs).
- Kubernetes is the platform that hosts Airflow‚Äôs components as containers, keeps them healthy, and lets you scale.

## üß± Components & Their Roles

> **Think of Airflow like an orchestra:** Each component plays a specific instrument, and Kubernetes is the conductor keeping everyone in sync!

| Component | Role | What It Does |
|-----------|------|---------------|
| **üåê Webserver** | UI & Control Panel | You enable/trigger DAGs, view runs, read logs |
| **üóìÔ∏è Scheduler** | Brain | Reads DAGs, decides which tasks run now, queues them |
| **üë∑ Worker(s)** | Executors | Pick tasks from queue, run your Python code |
| **üì® Redis** | Message Queue | Connects scheduler ‚ÜîÔ∏è workers (Celery broker) |
| **üíæ PostgreSQL** | Memory | Stores DAG runs, task states, connections, variables |
| **üìÅ Volumes** | Shared Storage | DAGs, plugins, and logs accessible to all pods |

## üó∫Ô∏è Visual Flow Diagram

> **See how data flows through the system!** Follow the arrows to understand the complete workflow.

```
           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ            Kubernetes Cluster              ‚îÇ
           ‚îÇ             (Namespace: airflow)           ‚îÇ
           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
           ‚îÇ                                            ‚îÇ
           ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
UI ‚Üí HTTP  ‚îÇ  ‚îÇ Airflow        ‚îÇ        ‚îÇ Scheduler  ‚îÇ  ‚îÇ
(you)      ‚îÇ  ‚îÇ Webserver      ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ (decides   ‚îÇ  ‚îÇ
           ‚îÇ  ‚îÇ (Deployment)   ‚îÇ        ‚îÇ what runs) ‚îÇ  ‚îÇ
           ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
           ‚îÇ         ‚îÇ                        ‚îÇ          ‚îÇ
           ‚îÇ         ‚îÇ reads DAGs             ‚îÇ enqueues ‚îÇ
           ‚îÇ         ‚îÇ & shows status         ‚îÇ tasks    ‚îÇ
           ‚îÇ         ‚îÇ                        ‚îÇ          ‚îÇ
           ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
           ‚îÇ  ‚îÇ DAGs/Plugins/  ‚îÇ     ‚îÇ Redis (broker)‚îÇ  ‚îÇ
           ‚îÇ  ‚îÇ Logs (Volumes) ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ Queue         ‚îÇ  ‚îÇ
           ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
           ‚îÇ                                            ‚îÇ
           ‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îÇ
           ‚îÇ                  ‚îÇ Worker(s)  ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ                  ‚îÇ Execute tasks from queue |
           ‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò            ‚îÇ
           ‚îÇ                                            ‚îÇ
           ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
           ‚îÇ  ‚îÇ PostgreSQL (Metadata DB)             ‚îÇ  ‚îÇ
           ‚îÇ  ‚îÇ DAG runs, task states, connections   ‚îÇ  ‚îÇ
           ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
           ‚îÇ                                            ‚îÇ
           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üîß Kubernetes Building Blocks

> **Kubernetes provides the infrastructure** that keeps Airflow running reliably at scale.

| K8s Resource | Purpose | Used For |
|--------------|---------|----------|
| **Pods/Deployments/StatefulSets** | Running containers | Webserver, scheduler, worker, redis, postgres |
| **Services** | Stable network addresses | Components talk to each other (`postgres`, `redis`, `airflow-webserver`) |
| **ConfigMaps** | Non-secret configuration | Airflow settings (executor type, DAGs folder) |
| **Secrets** | Sensitive values | Database URL, broker URL, passwords |
| **Volumes** | Persistent storage | DAGs, logs, plugins |
| **RBAC/ServiceAccount** | Permissions | Auth to run in the cluster |
| **Probes** | Health checks | K8s restarts unhealthy pods automatically |

## üìù Beginner Procedure (Why, What, Reasoning)

> **Follow these steps in order** for a smooth deployment. Each step builds on the previous one!

### 1Ô∏è‚É£ Prepare Kubernetes
- **Why**: Airflow needs a platform to run containers reliably.
- **What**: Enable Kubernetes in Docker Desktop; make sure `kubectl` works.
- **Reason**: K8s handles restarts, networking, and scaling for you.

2) Create Namespace & Secrets
- **Why**: Isolate resources; protect credentials.
- **What**: Use the `airflow` namespace; create the Secret with DB and broker URLs.
- **Reason**: Namespaces organize; Secrets keep passwords out of plain text configs.

3) Deploy PostgreSQL (Metadata DB)
- **Why**: Airflow tracks runs, task states, and settings in a database.
- **What**: Apply `kubernetes/postgres.yaml`; wait until ready.
- **Reason**: Without the DB, Airflow can‚Äôt remember anything long-term.

4) Deploy Redis (Celery Broker)
- **Why**: Connects scheduler and workers via a fast task queue.
- **What**: Included in `kubernetes/airflow.yaml`.
- **Reason**: Celery uses Redis; workers pull tasks from it.

5) Configure Airflow (ConfigMap + Secret)
- **Why**: Keep Airflow settings declarative and portable.
- **What**: Set executor (Celery), DAGs folder, broker/database URLs.
- **Reason**: Clean separation between images and environment-specific settings.

6) Deploy Airflow Components
- **Why**: Bring Webserver (UI), Scheduler (orchestration), Workers (execution) online.
- **What**: Apply `kubernetes/airflow.yaml`.
- **Reason**: You need all three to see UI, schedule, and execute tasks.

7) Validate Health
- **Why**: Catch issues early.
- **What**: `kubectl get pods`, `kubectl logs` (webserver/scheduler/worker).
- **Reason**: Ensures the stack is truly ready before using the UI.

8) Access Web UI
- **Why**: Operate Airflow (enable DAGs, trigger runs, inspect logs).
- **What**: Port-forward the webserver service.
  ```powershell
  kubectl port-forward svc/airflow-webserver 8080:8080 -n airflow
  # If 8080 is busy:
  kubectl port-forward svc/airflow-webserver 9090:8080 -n airflow
  ```
- **Reason**: Exposes the in-cluster service to your browser locally.

9) Run a DAG
- **Why**: Validate the full pipeline.
- **What**: Enable `demo_dag` or `etl_example_dag` in the UI; trigger; read logs.
- **Reason**: Confirms end-to-end: scheduler ‚Üí redis ‚Üí worker ‚Üí DB state.

10) Scale or Troubleshoot
- **Why**: Adapt capacity; fix problems.
- **What**: Scale workers; check probes; view logs; describe pods.
  ```powershell
  kubectl scale statefulset/airflow-worker -n airflow --replicas=3
  ```
- **Reason**: Workloads vary; Kubernetes lets you grow or self-heal.

## Quick Reference (PowerShell)
```powershell
kubectl apply -f "kubernetes/postgres.yaml"
kubectl wait --for=condition=ready pod -l app=postgres -n airflow --timeout=300s
kubectl apply -f "kubernetes/airflow.yaml"
kubectl get pods -n airflow

kubectl port-forward svc/airflow-webserver 8080:8080 -n airflow
kubectl port-forward svc/airflow-webserver 9090:8080 -n airflow

kubectl logs -f deployment/airflow-webserver -n airflow
kubectl logs -f statefulset/airflow-scheduler -n airflow
kubectl logs -f statefulset/airflow-worker -n airflow
kubectl describe pod <pod-name> -n airflow
```

## Why Kubernetes Helps
- Resilience: Probes restart unhealthy pods.
- Scaling: Add workers easily when jobs increase.
- Separation: Independent components; safer upgrades.
- Observability: One place (`kubectl`) to check status and logs.

## See Also
- `docs/QUICKSTART.md` ‚Äî Get running fast
- `kubernetes/README.md` ‚Äî Deployment guide
- `docs/HELM_MIGRATION.md` ‚Äî Switch to Helm
- `kubernetes/helm-values.yaml` ‚Äî Helm values aligned to manifests
