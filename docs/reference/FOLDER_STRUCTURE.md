# ğŸ“ Project Folder Structure Guide

Hey there! Welcome to your roadmap for navigating this Airflow project. This guide explains what goes where and whyâ€”so you'll never feel lost in the codebase! ğŸ§­

## ğŸ¯ Overview

This project follows industry-standard patterns for organizing Airflow code, making it easy for teams to collaborate and scale.

> **ğŸ’¡ Quick Tip:** Bookmark this page! You'll refer to it often when deciding where to put new files.

---

## ğŸ—‚ï¸ Directory Reference

### ğŸ—ï¸ `airflow_home/`
**Purpose:** Airflow configuration and logs directory

**Contents:**
- `airflow.cfg` - Main Airflow configuration file
- `webserver_config.py` - Web UI customization
- `airflow.db` - SQLite database (auto-created)
- `logs/` - Task execution logs (organized by DAG and task)

**When to modify:**
- Only modify `airflow.cfg` for environment-specific settings
- Leave `webserver_config.py` as-is for POC

---

### ğŸ¯ `dags/`
**Purpose:** Your Airflow DAG definitions live here

**Contents:**
- `__init__.py` - Package marker (required!)
- `demo_dag.py` - Simple starter DAG for learning
- `etl_example_dag.py` - Full ETL pipeline example

### âœ… Best Practices:

| Do This âœ… | Avoid This âŒ |
|-----------|-------------|
| One DAG per file or group related DAGs | Mixing unrelated workflows in one file |
| Use descriptive names: `daily_sales_etl.py` | Generic names like `dag1.py` or `test.py` |
| Add docstrings explaining DAG purpose | No documentation |
| Keep DAG files only in this folder | Scattered DAGs across project |
| Import from `src/` for business logic | All code inside DAG files |

> **âš ï¸ Warning:** Don't import from the `dags/` folder in other modulesâ€”it creates circular dependencies!

### ğŸš€ Adding Your First DAG:

1ï¸âƒ£ Create `my_first_dag.py` in this folder  
2ï¸âƒ£ Define your DAG with unique `dag_id`  
3ï¸âƒ£ Refresh Airflow UI (wait ~30 seconds)  
4ï¸âƒ£ Your DAG appears in the list! ğŸ‰

---

### ğŸ’» `src/`
**Purpose:** Your application business logic (reusable, testable, Airflow-agnostic code)

> **ğŸ¯ Key Principle:** Keep business logic separate from orchestration logic. DAGs define the workflow; `src/` does the actual work.

**Structure:**
```
src/ ğŸ’»
â”œâ”€â”€ __init__.py
â”œâ”€â”€ extract/ ğŸ“¥         # Data extraction logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ extract_from_source_a.py
â”œâ”€â”€ transform/ âš™ï¸       # Data transformation logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ transform_sales_data.py
â”œâ”€â”€ load/ ğŸ“¤             # Data loading logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ load_to_dw.py
â””â”€â”€ utils/ ğŸ”§            # Shared utilities
    â”œâ”€â”€ __init__.py
    â””â”€â”€ helpers.py
```

### âœ… Best Practices:

- âœ¨ **Separation of Concerns:** Business logic here, orchestration in DAGs
- ğŸ§ª **Reusable Functions:** Write functions that can work standalone
- ğŸ§™ **Testable Code:** Functions should be unit-testable without Airflow
- ğŸ“ **Documentation:** Add docstrings to all functions
- ğŸ“¦ **Clean Imports:** Use in DAGs: `from src.extract.extract_from_source_a import extract_function`

> **ğŸ’¡ Pro Tip:** If you can test a function without starting Airflow, you've organized it correctly!**Example Structure for Growing Project:**
```
src/
â”œâ”€â”€ connectors/       # Database/API connections
â”œâ”€â”€ schemas/          # Data schemas and validation
â”œâ”€â”€ processors/       # Data processing logic
â””â”€â”€ logging/          # Custom logging utilities
```

---

### `data/`
**Purpose:** Input and output data storage

**Structure:**
```
data/
â”œâ”€â”€ raw/                          # Input data (read-only)
â”‚   â””â”€â”€ sample_source_a.csv
â”œâ”€â”€ processed/                    # Transformed data
â”‚   â””â”€â”€ sales_daily_summary.csv
â”œâ”€â”€ staging/                      # Intermediate data
â””â”€â”€ archive/                      # Historical data
```

**Best Practices:**
- âœ… `raw/` - Never modify, treat as read-only
- âœ… `processed/` - Task outputs go here
- âœ… `staging/` - Temporary files between tasks
- âœ… `archive/` - Keep historical data for auditing
- âŒ Don't commit large files to git (add to .gitignore)

**File Organization Example:**
```
data/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ 2024-01/
â”‚   â”œâ”€â”€ 2024-02/
â”‚   â””â”€â”€ ...
â””â”€â”€ processed/
	â”œâ”€â”€ daily_summary_2024-01-01.csv
	â”œâ”€â”€ daily_summary_2024-01-02.csv
	â””â”€â”€ ...
```

---

### `docker/`
**Purpose:** Docker containerization files

**Contents:**
- `docker-compose.yaml` - Multi-container orchestration

**When to use:**
- Deploy Airflow with PostgreSQL database
- Share development environment with team
- Replicate production setup locally

**Quick Start:**
```bash
cd docker
docker-compose up
```

---

### `plugins/`
**Purpose:** Custom Airflow extensions

**Structure:**
```
plugins/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ hooks/                        # Custom database connectors
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ my_custom_hook.py
â”œâ”€â”€ operators/                    # Custom operators
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ my_custom_operator.py
â””â”€â”€ sensors/                      # Custom sensors
	â”œâ”€â”€ __init__.py
	â””â”€â”€ my_custom_sensor.py
```

**When to use:**
- Reusable components across multiple DAGs
- Custom integration with external systems
- Shared business logic for operators

**Example Custom Operator:**
```python
# plugins/operators/my_operator.py
from airflow.models import BaseOperator

class MyCustomOperator(BaseOperator):
	def execute(self, context):
		# Your logic here
		pass
```

---

### `config/`
**Purpose:** Configuration files for application

**Suggested Contents:**
```
config/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ dev.py              # Development settings
â”œâ”€â”€ prod.py             # Production settings
â”œâ”€â”€ database.py         # Database configurations
â””â”€â”€ logging.py          # Logging configurations
```

**Example:**
```python
# config/dev.py
DEBUG = True
LOG_LEVEL = 'DEBUG'
DB_HOST = 'localhost'
```

---

### `reports/`
**Purpose:** Generated output reports and figures

**Structure:**
```
reports/
â”œâ”€â”€ figures/            # Visualizations
â”‚   â”œâ”€â”€ daily_sales.png
â”‚   â””â”€â”€ trends.pdf
â”œâ”€â”€ summaries/          # Text reports
â”‚   â””â”€â”€ 2024-01-01_daily_summary.txt
â””â”€â”€ dashboards/         # Dashboard configurations
```

---

### `tests/`
**Purpose:** Unit and integration tests

**Structure:**
```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_extract.py     # Test extract functions
â”œâ”€â”€ test_transform.py   # Test transform functions
â”œâ”€â”€ test_load.py        # Test load functions
â””â”€â”€ test_dags.py        # Test DAG structure and dependencies
```

**Example Test:**
```python
# tests/test_extract.py
import pytest
from src.extract.extract_from_source_a import extract_from_source_a

def test_extract_returns_count():
	result = extract_from_source_a()
	assert isinstance(result, int)
```

**Run Tests:**
```bash
pytest tests/
```

---

### `logs/`
**Purpose:** Airflow execution logs (auto-generated)

**Structure:**
```
logs/
â”œâ”€â”€ dag_processor_manager/
â”œâ”€â”€ scheduler/
â””â”€â”€ dags/
	â””â”€â”€ demo_dag/
		â”œâ”€â”€ start/
		â”‚   â””â”€â”€ 2024-01-01T08:00:00+00:00/
		â”‚       â””â”€â”€ attempt=1.log
		â””â”€â”€ end/
			â””â”€â”€ 2024-01-01T08:00:00+00:00/
				â””â”€â”€ attempt=1.log
```

**Notes:**
- Auto-generated by Airflow
- Safe to delete (logs can be recreated)
- Add to `.gitignore`

---

### `docs/`
**Purpose:** Project documentation

**Suggested Contents:**
```
docs/
â”œâ”€â”€ architecture.md              # System design
â”œâ”€â”€ deployment.md                # How to deploy
â”œâ”€â”€ troubleshooting.md           # Common issues
â””â”€â”€ data_dictionary.md           # Data field definitions
```

---

## ğŸ“‹ File Organization Best Practices

### Adding a New Feature

**Step 1: Create business logic**
```
src/my_feature/
â”œâ”€â”€ __init__.py
â””â”€â”€ processor.py
```

**Step 2: Create DAG to use it**
```
dags/
â””â”€â”€ my_feature_dag.py
```

**Step 3: Add data**
```
data/
â”œâ”€â”€ raw/my_data.csv
â””â”€â”€ processed/
```

**Step 4: Add tests**
```
tests/
â””â”€â”€ test_my_feature.py
```

### Growth Path

```
POC Phase:
â”œâ”€â”€ dags/demo_dag.py
â”œâ”€â”€ src/extract/
â””â”€â”€ data/raw/

Early Production:
â”œâ”€â”€ dags/daily_etl_dag.py
â”œâ”€â”€ dags/hourly_etl_dag.py
â”œâ”€â”€ src/extract/, transform/, load/
â”œâ”€â”€ plugins/operators/
â”œâ”€â”€ tests/
â””â”€â”€ config/

Mature Production:
â”œâ”€â”€ dags/ (multiple files)
â”œâ”€â”€ src/ (organized by domain)
â”œâ”€â”€ plugins/ (custom operators/hooks)
â”œâ”€â”€ config/ (env-specific)
â”œâ”€â”€ tests/ (comprehensive)
â”œâ”€â”€ docs/ (architecture, runbooks)
â””â”€â”€ monitoring/ (alerting, metrics)
```

---

## ğŸš€ How to Add Files to Source Control

### Create `.gitignore`
```
# Airflow
airflow.db
airflow_home/logs/
airflow_home/plugins/

# Data
data/raw/*
data/processed/*
data/staging/*

# Python
__pycache__/
*.pyc
.venv/
venv/

# IDE
.vscode/
.idea/
*.swp

# OS
.DS_Store
Thumbs.db
```

### Track Important Files
```bash
git add dags/
git add src/
git add tests/
git add config/
git add README.md
git add docs/
```

---

## ğŸ¯ Quick Reference

| Folder | Purpose | Who Creates | Modify? |
|--------|---------|-------------|---------|
| `airflow_home/` | Config & logs | Airflow | Rarely |
| `dags/` | DAG definitions | You | Often |
| `src/` | Business logic | You | Often |
| `data/` | Files in/out | Tasks | Often |
| `docker/` | Deployment | You | Rarely |
| `plugins/` | Extensions | You | Sometimes |
| `config/` | App config | You | Sometimes |
| `tests/` | Unit tests | You | Often |
| `reports/` | Generated reports | Tasks | Often |
| `docs/` | Documentation | You | Sometimes |
| `logs/` | Execution logs | Airflow | Never |

---

## ğŸ“ Troubleshooting

### "Module not found" error
- Check file is in correct folder
- Check `__init__.py` exists in package folders
- Check import path matches folder structure

### "DAG not appearing"
- Verify file is in `dags/` folder
- Check for Python syntax errors
- Check `dag_id` is unique

### "Too many files in root"
- Create subdirectories under `src/`
- Group related DAGs into category folders
- Use clear naming conventions

---

## âœ… Your Project is Well-Organized!

Your current structure is clean and ready to scale:
```
âœ“ Separation of concerns (dags/ vs src/)
âœ“ Data organization (raw/ vs processed/)
âœ“ Documentation (README, docs/*)
âœ“ Docker support ready
âœ“ Space for custom plugins
```

Good foundation for learning and growing your Airflow POC! ğŸš€
